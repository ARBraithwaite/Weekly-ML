{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to TensorFlow\n",
    "\n",
    "TensorFlow is an opensource machine learning framework developed by Google. At its heart is a library for performing multi-dimensional matrix algebra, which is the basis of most machine learning techniques. It works by breaking up the algebraic expressions into a series of simple mathematical operations, which are linked together in a computational graph (or 'dataflow graph'). This explicitly defines the dependancies between the operations and allows for easier optimisation and parallelisation.  \n",
    "\n",
    "This tutorial will show you several ways to build a Convolution Neural Network (CNN) in TensorFlow, and explain the pros and cons of each. The tutorial will not, however, go into the theory of how a CNN works. As is tradition with CNN tutorials, the MNIST dataset will be used as the example task.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get MNIST dataset and normalise pixel values.\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Keras Interface\n",
    "Keras was one of the original high level APIs to machine learning libraries, and has since been subsumed into TensorFlow. It provides a very easy to use high-level API that is still relatively powerful. To achieve this, it provided two methods to define a neural network. The first of these is the Sequential API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sequential model.\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "# Compile model, specifying the training configuration.\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train for 5 epochs and then test the model.\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=5)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all the code you need to create and train a neural network in TensorFlow. Admittedly, it is a very simple network, but one none the less. The network is stored in the variable `model` and is made up of two fully connected layers (`tf.keras.layers.Dense`), separated by a dropout layer with probability $\\frac{1}{5}$. \n",
    "\n",
    "As with all high-level APIs, with simplicity comes restrictions. If your network is not comprised of a simple series of layers, then you will find it very difficult to define it this way. Because of this, TensorFlow also has a Functional API. This allows you to create more complex models with attributes such as multiple inputs/outputs, shared layers and non-sequential data flows (residual connections). A network can be defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define a placeholder for the inputs.\n",
    "inputs = tf.keras.Input(shape=(28, 28))\n",
    "\n",
    "# Define the model. Note: Each layer instance is callable on a tensor, and returns a tensor.\n",
    "x = tf.keras.layers.Flatten()(inputs)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "predictions = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Compile model, specifying the training configuration.\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train for 5 epochs and then test the model.\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=5)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network is exactly the same as the one in the Sequential example above. You can therefore see that it is not quite as clean a definition. In this API each layer instance is callable and returns a tensor. Furthermore, the input tensors and output tensors are used to define a `tf.keras.Model` instance, however, this is trained just like the Sequential model. Despite the increased comlexity, the Funtional API allows you to do the following, which is the way the majority of all your future networks should be laid out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network as a subclass of tf.keras.Model\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyModel, self).__init__(name='my_model')\n",
    "        self.num_classes = num_classes\n",
    "        # Define your layers here.\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(512, activation='relu')\n",
    "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "        self.fc2 = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Define your forward pass here.\n",
    "        x = self.flatten(inputs)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "    \n",
    "# Initial an instance of your model\n",
    "model = MyModel(num_classes=10)\n",
    "\n",
    "# Compile model, specifying the training configuration.\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train for 5 epochs and then test the model.\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=5)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Functional API lets us build fully-customizable models by subclassing `tf.keras.Model` and defining our own forward pass. We create the model's layers in the `__init__` method and set them as attributes of the class instance. Then define the dependancies between them, the forward pass, in the `call` method.\n",
    "\n",
    "Model subclassing is particularly useful when eager execution is enabled since the forward pass can be written imperatively, however, while it offers flexibility, the additional complexity provides more opportunities for user errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more infomation on TensorFlow and Keras, please see: https://www.tensorflow.org/guide/keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Advanced Capabilities\n",
    "In this next section, we will look at several additional aspects of the Keras interface that provide some more advance capabilities. \n",
    "\n",
    "### Callbacks\n",
    "Callbacks are objects that extend the training procedure. This includes capabilities such as checkpointing, LR scheduling, early stopping and metric logging. It is also possible to create your own custom callbacks. Callbacks are passed as a list to the a model's `fit` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial another instance of the model\n",
    "model2 = MyModel(num_classes=10)\n",
    "\n",
    "# Compile model, specifying the training configuration.\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define list of callback objects\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='./checkpoints', save_weights_only=True),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "# Train for 5 epochs (passing in callbacks as a parameter) and then test the model.\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=5, callbacks=callbacks)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Loading Models\n",
    "Saving and loading models is obviously important otherwise you would never be able to use the models you trained. It is also import for when you need to use more advanced techniques, such as fine-tuning.\n",
    "\n",
    "Below displays how to save and load the model weights. It should be noted that the model architecture will have to be defined before the weights can be loaded into it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights to a TensorFlow Checkpoint file\n",
    "model.save_weights('./weights/my_model')\n",
    "\n",
    "# Restore the model's state,\n",
    "# this requires a model with the same architecture.\n",
    "model.load_weights('./weights/my_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
